{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Application-specific imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../config/\")\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../metaflow/\")\n",
    "import preprocess_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## General "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load the set from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = spark.read.json('../dataset/M20_cards.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Preprocess "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Filter out duplicate cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered = preprocess_fn.remove_duplicate_cards(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of cards 329\n"
     ]
    }
   ],
   "source": [
    "num_cards = df_filtered.count()\n",
    "print(f\"Final number of cards {num_cards}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered = preprocess_fn.drop_columns(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Filter the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn('filtered_text',\n",
    "                                     preprocess_fn.udf_filter_text('name', 'text')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Explode the selected arrays in a string, separated by \",\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered = preprocess_fn.explode_to_strs(df_filtered,\n",
    "                                            [\"colorIdentity\", \"types\", \"subtypes\", \"supertypes\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Encode newly created strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered = preprocess_fn.encode_strings(df_filtered, [\"rarity\", \"str_colorIdentity\", \"str_types\", \"str_subtypes\", \"str_supertypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_model_rarity' to '/mtgp/artifacts/spark_models/stringindexer_model_rarity'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_model_str_colorIdentity' to '/mtgp/artifacts/spark_models/stringindexer_model_str_colorIdentity'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_model_str_subtypes' to '/mtgp/artifacts/spark_models/stringindexer_model_str_subtypes'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_model_str_supertypes' to '/mtgp/artifacts/spark_models/stringindexer_model_str_supertypes'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_model_str_types' to '/mtgp/artifacts/spark_models/stringindexer_model_str_types'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_rarity' to '/mtgp/artifacts/spark_models/stringindexer_rarity'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_str_colorIdentity' to '/mtgp/artifacts/spark_models/stringindexer_str_colorIdentity'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_str_subtypes' to '/mtgp/artifacts/spark_models/stringindexer_str_subtypes'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_str_supertypes' to '/mtgp/artifacts/spark_models/stringindexer_str_supertypes'; unable to remove target: Directory not empty\n",
      "mv: inter-device move failed: '/tmp/pyspark/stringindexer_str_types' to '/mtgp/artifacts/spark_models/stringindexer_str_types'; unable to remove target: Directory not empty\n"
     ]
    }
   ],
   "source": [
    "mv /tmp/pyspark/stringindexer* /mtgp/artifacts/spark_models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Count the number of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn(\"num_colors\", fn.size(\"colors\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#  Create an SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_filtered.createOrReplaceTempView(\"cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tbl = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        CAST(number as Integer), \n",
    "        rarity,\n",
    "        name,\n",
    "        CAST(convertedManaCost as Integer),\n",
    "        CAST(num_colors as Integer) as numColors,\n",
    "        str_colorIdentity as colorIdentity,\n",
    "        CAST(encoded_str_colorIdentity as Integer) as encodedColorIdentity,\n",
    "        str_types as types,\n",
    "        CAST(encoded_str_types as Integer) as encodedTypes,\n",
    "        str_subtypes as subTypes,\n",
    "        CAST(encoded_str_subtypes as Integer) as encodedSubTypes,\n",
    "        str_supertypes as superTypes,\n",
    "        CAST(encoded_str_supertypes as Integer) as encodedSuperTypes,\n",
    "        text as originalText,\n",
    "        filtered_text as filteredText,\n",
    "        CAST(power as Integer),\n",
    "        CAST(toughness as Integer)\n",
    "    FROM\n",
    "        cards\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Save to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tbl.write.mode(\"overwrite\").parquet(f\"{config.TEMP}/M20_cards.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## this fails\n",
    "# tbl.write.mode(\"overwrite\").parquet('dataset/THB_cards.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cp -R \"/tmp/M20_cards.parquet\" \"../artifacts/dataset/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showcode": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
