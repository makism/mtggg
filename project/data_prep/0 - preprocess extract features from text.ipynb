{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the set from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('../dataset/M20_cards.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out duplicate cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_names = df.select(['number', 'name']).toPandas()\n",
    "unique_names, indices, counts = np.unique(pd_names['name'], return_index=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_unique_names = pd_names.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = spark.createDataFrame(pd_unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filter.join(df, on='number', how='left').drop(df_filter.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cards  = df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of cards 329\n"
     ]
    }
   ],
   "source": [
    "print(f'Final number of cards {num_cards}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['colorIdentity','convertedManaCost','colors','manaCost','name','number','text','power','rarity','subtypes','supertypes','toughness', 'types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = list(set(df.columns) - set(keep_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(*remove_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"When {CARDNAME} enters the battlefield\": \"ETB_EFFECT\",\n",
    "    \n",
    "    \"Flash (You may cast this spell any time you could cast an instant.)\": \"FLASH\",\n",
    "    \"Flash\": \"FLASH\",\n",
    "    \n",
    "    \"Reach (This creature can block creatures with flying.)\": \"REACH\",\n",
    "    \"Reach\": \"REACH\",\n",
    "    \n",
    "    \"Flying (This creature can't be blocked except by creatures with flying or reach.)\": \"FLYING\",\n",
    "    \"Flying\": \"FLYING\",\n",
    "    \n",
    "    \"Haste (This creature can attack and {T} as soon as it comes under your control.)\": \"HASTE\",\n",
    "    \"Haste\": \"HASTE\",\n",
    "    \n",
    "    \"Trample (This creature can deal excess combat damage to the player or planeswalker it's attacking.)\": \"TRAMPLE\",\n",
    "    \"Trample\": \"TRAMPLE\",\n",
    "    \n",
    "    \"Vigilance (Attacking doesn't cause this creature to tap.)\": \"VIGILANCE\",\n",
    "    \"Vigilance\": \"VIGILANCE\",\n",
    "\n",
    "    \"Double strike (This creature deals both first-strike and regular combat damage.)\": \"DOUBLE_STRIKE\",\n",
    "    \"Double strike\": \"DOUBLE_STRIKE\",\n",
    "\n",
    "    \"Deathtouch (Any amount of damage this deals to a creature is enough to destroy it.)\": \"DEATHTOUCH\",\n",
    "    \"Deathtouch\": \"DEATHTOUCH\",\n",
    "    \n",
    "    \"Protection from green (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything green.)\": \"PROTECTION_FROM_GREEN\",\n",
    "    \"Protection from red (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything red.)\": \"PROTECTION_FROM_RED\",\n",
    "    \"Protection from black (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything black.)\": \"PROTECTION_FROM_BLACK\",\n",
    "    \"Protection from blue (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything blue.)\": \"PROTECTION_FROM_BLUE\",\n",
    "    \"Protection from white (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything white.)\": \"PROTECTION_FROM_WHITE\",\n",
    "    \n",
    "    \"(As this Saga enters and after your draw step, add a lore counter. Sacrifice after III.)\": \"SAGA_3\",\n",
    "    \"(As this Saga enters and after your draw step, add a lore counter. Sacrifice after IV.)\": \"SAGA_4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.udf(returnType=t.ArrayType(t.StringType()))\n",
    "def udf_filter_text(name, text):\n",
    "    feats = list()\n",
    "    if isinstance(text, str):\n",
    "        new_text = text.replace(name, 'CARDNAME')\n",
    "        for line in new_text.split('\\n'):\n",
    "            for rule, replace in rules.items():\n",
    "                if line.startswith(rule):\n",
    "                    line = line.replace(rule, replace)\n",
    "                    feats.append(replace)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"text_features\" in df_filtered.columns:\n",
    "    df_filtered = df_filtered.drop(\"text_features\")\n",
    "\n",
    "df_filtered = df_filtered.withColumn('text_features', udf_filter_text('name', 'text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_feats = df_filtered.select(\"text_features\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text_feats = [items for items in all_text_feats if len(items) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "filtered_text_feats = list(itertools.chain.from_iterable(filtered_text_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = preprocessing.LabelEncoder().fit(filtered_text_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fn.udf(returnType=t.ArrayType(t.IntegerType()))\n",
    "def text_to_vector(text_features):\n",
    "    if len(text_features) > 0:\n",
    "        enc_list = list()\n",
    "        for item in text_features:\n",
    "            item = str(item)\n",
    "            encoded = lenc.transform([item])\n",
    "            encoded = int(encoded[0])\n",
    "            enc_list.append(encoded)\n",
    "            \n",
    "            print(f\"{item} \\t {encoded}\")\n",
    "        return enc_list\n",
    "    return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"text_features_vect\" in df_filtered.columns:\n",
    "    df_filtered = df_filtered.drop(\"text_features_vect\")\n",
    "\n",
    "df_filtered = df_filtered.withColumn(\"text_features_vect\", text_to_vector(\"text_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|text_features_vect|\n",
      "+------------------+\n",
      "|            [2, 3]|\n",
      "|              [12]|\n",
      "|                []|\n",
      "|               [1]|\n",
      "|               [6]|\n",
      "|               [3]|\n",
      "|               [5]|\n",
      "|               [9]|\n",
      "|               [4]|\n",
      "|               [7]|\n",
      "|              [10]|\n",
      "|           [3, 12]|\n",
      "|              [11]|\n",
      "|            [3, 8]|\n",
      "|            [3, 4]|\n",
      "|               [2]|\n",
      "|               [0]|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.select(\"text_features_vect\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode the selected arrays in a string, separated by \",\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_to_strs(df, cols):\n",
    "    for col in cols:\n",
    "        df_edited = df.selectExpr([\"number\", col]).select('number', fn.expr(f\"concat_ws(',', {col})\").alias(f\"str_{col}\"))\n",
    "        df = df.join(df_edited, on='number')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = explode_to_strs(df_filtered, [\"colorIdentity\", \"types\", \"subtypes\", \"supertypes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode newly created strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_strings(df, cols):\n",
    "    for col in cols:\n",
    "        indexer = StringIndexer(inputCol=f\"{col}\", outputCol=f\"encoded_{col}\", stringOrderType='alphabetAsc')\n",
    "        model = indexer.fit(df)\n",
    "        df = model.transform(df)\n",
    "        \n",
    "#         indexer.save(f\"/tmp/pyspark/stringindexer_{col}\")\n",
    "#         model.save(f\"/tmp/pyspark/stringindexer_model_{col}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = encode_strings(df_filtered, [\"rarity\", \"str_colorIdentity\", \"str_types\", \"str_subtypes\", \"str_supertypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+-----------------+\n",
      "|               types|        str_types|encoded_str_types|\n",
      "+--------------------+-----------------+-----------------+\n",
      "|          [Artifact]|         Artifact|              0.0|\n",
      "|      [Planeswalker]|     Planeswalker|              6.0|\n",
      "|[Artifact, Creature]|Artifact,Creature|              1.0|\n",
      "|              [Land]|             Land|              5.0|\n",
      "|           [Instant]|          Instant|              4.0|\n",
      "|           [Sorcery]|          Sorcery|              7.0|\n",
      "|          [Creature]|         Creature|              2.0|\n",
      "|       [Enchantment]|      Enchantment|              3.0|\n",
      "+--------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.select([\"types\", \"str_types\", \"encoded_str_types\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn(\"num_colors\", fn.size(\"colors\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an SQL table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.createOrReplaceTempView(\"cards_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        CAST(number as Integer),\n",
    "        rarity,\n",
    "        text_features_vect,\n",
    "        CAST(convertedManaCost as Integer),\n",
    "        CAST(num_colors as Integer) as numColors,\n",
    "        str_colorIdentity as colorIdentity,\n",
    "        CAST(encoded_str_colorIdentity as Integer) as encodedColorIdentity,\n",
    "        str_types as types,\n",
    "        CAST(encoded_str_types as Integer) as encodedTypes,\n",
    "        str_subtypes as subTypes,\n",
    "        CAST(encoded_str_subtypes as Integer) as encodedSubTypes,\n",
    "        str_supertypes as superTypes,\n",
    "        CAST(encoded_str_supertypes as Integer) as encodedSuperTypes,\n",
    "        CAST(power as Integer),\n",
    "        CAST(toughness as Integer)\n",
    "\n",
    "    FROM\n",
    "        cards_features\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|text_features_vect|\n",
      "+------------------+\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|                []|\n",
      "|               [3]|\n",
      "|                []|\n",
      "|               [3]|\n",
      "|                []|\n",
      "|               [3]|\n",
      "|              [11]|\n",
      "|               [0]|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        text_features_vect\n",
    "    FROM\n",
    "        cards_features\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(number=296, rarity='uncommon', text_features_vect=[], convertedManaCost=5, numColors=1, colorIdentity='R', encodedColorIdentity=16, types='Creature', encodedTypes=2, subTypes='Elemental', encodedSubTypes=25, superTypes='', encodedSuperTypes=0, power=5, toughness=4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.write.mode(\"overwrite\").parquet('/tmp/M20_cards_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf \"../dataset/M20_cards_features.parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv \"/tmp/M20_cards_features.parquet\" \"../dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
