{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the set from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'dataset/THB.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file, 'r') as fp:\n",
    "    raw_data = json.load(fp)\n",
    "    cards = raw_data['cards']\n",
    "\n",
    "n = len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump the cards in a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/THB_cards.json', 'w') as fp:\n",
    "    json.dump(cards, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"When {CARDNAME} enters the battlefiTHB\": \"ETB_EFFECT\",\n",
    "    \n",
    "    \"Flash (You may cast this spell any time you could cast an instant.)\": \"FLASH\",\n",
    "    \"Flash\": \"FLASH\",\n",
    "    \n",
    "    \"Reach (This creature can block creatures with flying.)\": \"REACH\",\n",
    "    \"Reach\": \"REACH\",\n",
    "    \n",
    "    \"Flying (This creature can't be blocked except by creatures with flying or reach.)\": \"FLYING\",\n",
    "    \"Flying\": \"FLYING\",\n",
    "    \n",
    "    \"Haste (This creature can attack and {T} as soon as it comes under your control.)\": \"HASTE\",\n",
    "    \"Haste\": \"HASTE\",\n",
    "    \n",
    "    \"Trample (This creature can deal excess combat damage to the player or planeswalker it's attacking.)\": \"TRAMPLE\",\n",
    "    \"Trample\": \"TRAMPLE\",\n",
    "    \n",
    "    \"Vigilance (Attacking doesn't cause this creature to tap.)\": \"VIGILANCE\",\n",
    "    \"Vigilance\": \" VIGILANCE\",\n",
    "\n",
    "    \"Double strike (This creature deals both first-strike and regular combat damage.)\": \"DOUBLE_STRIKE\",\n",
    "    \"Double strike\": \"DOUBLE_STRIKE\",\n",
    "\n",
    "    \"Deathtouch (Any amount of damage this deals to a creature is enough to destroy it.)\": \"DEATHTOUCH\",\n",
    "    \"Deathtouch\": \"DEATHTOUCH\",\n",
    "    \n",
    "    \"Protection from green (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything green.)\": \"PROTECTION_FROM_GREEN\",\n",
    "    \"Protection from red (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything red.)\": \"PROTECTION_FROM_RED\",\n",
    "    \"Protection from black (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything black.)\": \"PROTECTION_FROM_BLACK\",\n",
    "    \"Protection from blue (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything blue.)\": \"PROTECTION_FROM_BLUE\",\n",
    "    \"Protection from white (This creature can't be blocked, targeted, dealt damage, enchanted, or equipped by anything white.)\": \"PROTECTION_FROM_WHITE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def udf_filter_text(name, text):\n",
    "    if isinstance(text, str):\n",
    "        new_text = text\n",
    "        new_text = new_text.replace(name, 'CARDNAME')\n",
    "        for line in new_text:\n",
    "            for rule, replace in rules.items():\n",
    "                new_text = new_text.replace(rule, replace)\n",
    "\n",
    "        return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('dataset/THB_cards.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out duplicate cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_names = df.select(['number', 'name']).toPandas()\n",
    "unique_names, indices, counts = np.unique(pd_names['name'], return_index=True, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_unique_names = pd_names.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = spark.createDataFrame(pd_unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filter.join(df, on='number', how='left').drop(df_filter.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cards  = df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Final number of cards {num_cards}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['colorIdentity','convertedManaCost','colors','manaCost','name','number','text','power','rarity','subtypes','supertypes','toughness', 'types']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = list(set(df.columns) - set(keep_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(*remove_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn('filtered_text', udf_filter_text('name', 'text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explode the selected arrays in a string, separated by \",\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_to_strs(df, cols):\n",
    "    for col in cols:\n",
    "        df_edited = df.selectExpr([\"number\", col]).select('number', fn.expr(f\"concat_ws(',', {col})\").alias(f\"str_{col}\"))\n",
    "        df = df.join(df_edited, on='number')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = explode_to_strs(df_filtered, [\"colorIdentity\", \"types\", \"subtypes\", \"supertypes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode newly created strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn + pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import sklearn\n",
    "# from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_colorId = df_filtered.select(\"str_colorIdentity\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_allColorIds = df_filtered.select(\"str_colorIdentity\").toPandas()\n",
    "# pd_colorIds = df_colorId.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder().fit(pd_colorIds)\n",
    "# encoded_colorIds = le.transform(pd_allColorIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_colorIds = pd.DataFrame(encoded_colorIds, columns=['encoded_colorIdentity'])\n",
    "# pd_colorIds['number'] = df_filtered.select(\"number\").toPandas().astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded_colorIds = spark.createDataFrame(pd_colorIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered = df_filtered.join(df_encoded_colorIds, on='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spark + ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_strings(df, cols):\n",
    "    for col in cols:\n",
    "        indexer = StringIndexer(inputCol=f\"{col}\", outputCol=f\"encoded_{col}\", stringOrderType='alphabetAsc')\n",
    "        model = indexer.fit(df)\n",
    "        df = model.transform(df)\n",
    "        \n",
    "        indexer.save(f\"/tmp/pyspark/stringindexer_{col}\")\n",
    "        model.save(f\"/tmp/pyspark/stringindexer_model_{col}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = encode_strings(df_filtered, [\"rarity\", \"str_colorIdentity\", \"str_types\", \"str_subtypes\", \"str_supertypes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.select([\"types\", \"str_types\", \"encoded_str_types\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf \"models/pyspark/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv \"/tmp/pyspark/\" \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered.select([\"str_colorIdentity\", \"encoded_colorIdentity\"]).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered.select([\"str_colorIdentity\", \"encoded_colorIdentity\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn(\"num_colors\", fn.size(\"colors\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the dataframe / dropcolumns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create an SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.createOrReplaceTempView(\"cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        CAST(number as Integer), \n",
    "        rarity,\n",
    "        name,\n",
    "        CAST(convertedManaCost as Integer),\n",
    "        CAST(num_colors as Integer) as numColors,\n",
    "        str_colorIdentity as colorIdentity,\n",
    "        CAST(encoded_str_colorIdentity as Integer) as encodedColorIdentity,\n",
    "        str_types as types,\n",
    "        CAST(encoded_str_types as Integer) as encodedTypes,\n",
    "        str_subtypes as subTypes,\n",
    "        CAST(encoded_str_subtypes as Integer) as encodedSubTypes,\n",
    "        str_supertypes as superTypes,\n",
    "        CAST(encoded_str_supertypes as Integer) as encodedSuperTypes,\n",
    "        text as originalText,\n",
    "        filtered_text as filteredText,\n",
    "        CAST(power as Integer),\n",
    "        CAST(toughness as Integer)\n",
    "    FROM\n",
    "        cards\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.write.mode(\"overwrite\").parquet('/tmp/THB_cards.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this fails\n",
    "# tbl.write.mode(\"overwrite\").parquet('dataset/THB_cards.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf \"dataset/THB_cards.parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv \"/tmp/THB_cards.parquet\" \"dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
